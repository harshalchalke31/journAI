{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Projects\\\\python\\\\journAI'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "import torch\n",
    "# **1Ô∏è‚É£ Define Local Model Path**\n",
    "local_model_path = \"./models/sdxl-turbo_local\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # **2Ô∏è‚É£ Download & Store Model Locally (Only Runs Once)**\n",
    "# def download_model():\n",
    "#     \"\"\"Download SDXL Turbo from Hugging Face and save locally.\"\"\"\n",
    "#     print(\"‚è≥ Downloading SDXL Turbo...\")\n",
    "#     pipeline = DiffusionPipeline.from_pretrained(\n",
    "#         \"stabilityai/sdxl-turbo\",\n",
    "#         torch_dtype=torch.float16,  # Use FP16 for speed & efficiency\n",
    "#         variant=\"fp16\"\n",
    "#     )\n",
    "#     pipeline.save_pretrained(local_model_path)\n",
    "#     print(f\"‚úÖ Model downloaded and saved locally at {local_model_path}\")\n",
    "\n",
    "# # Run only if the model is not downloaded\n",
    "# try:\n",
    "#     with open(f\"{local_model_path}/model_index.json\", \"r\"):\n",
    "#         print(\"‚úÖ SDXL Turbo model already exists locally.\")\n",
    "# except FileNotFoundError:\n",
    "#     download_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **3Ô∏è‚É£ Load Model from Local Storage with Optimizations**\n",
    "def load_model():\n",
    "    \"\"\"Load SDXL Turbo from local storage with optimizations.\"\"\"\n",
    "    print(\"‚è≥ Loading SDXL Turbo with optimizations...\")\n",
    "    \n",
    "    pipeline = DiffusionPipeline.from_pretrained(\n",
    "        local_model_path,\n",
    "        torch_dtype=torch.float16  # FP16 for faster inference\n",
    "    ).to(\"cuda\")  # Move model to GPU\n",
    "\n",
    "    # ‚úÖ Enable xFormers for Memory Optimization\n",
    "    # pipeline.enable_xformers_memory_efficient_attention()\n",
    "\n",
    "    # ‚úÖ Use FP16 Execution for Faster Performance\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    print(\"‚úÖ Model loaded successfully with optimizations!\")\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "# **4Ô∏è‚É£ Generate Image**\n",
    "def generate_image(prompt,image_path=\"./assets/output.jpg\"):\n",
    "    \"\"\"Generates an image using SDXL Turbo with an optimized pipeline.\"\"\"\n",
    "    pipeline = load_model()\n",
    "\n",
    "    print(f\"üé® Generating image for: '{prompt}' ...\")\n",
    "    image = pipeline(prompt, num_inference_steps=1, guidance_scale=0.0).images[0]\n",
    "\n",
    "    image.save(image_path)\n",
    "    print(f\"‚úÖ Image saved as {image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Loading SDXL Turbo with optimizations...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b447e6be7cd4afb87be1a76b624c7f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded successfully with optimizations!\n",
      "üé® Generating image for: 'World of the witcher, fighting wild hunt.' ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34085e78d44a4529a7ba9e37100cbead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Image saved as ./assets/witcher_wildhunt.jpg\n"
     ]
    }
   ],
   "source": [
    "image_path = \"./assets/witcher_wildhunt.jpg\"\n",
    "prompt = \"World of the witcher, fighting wild hunt.\"\n",
    "generate_image(prompt,image_path=image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mainenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
