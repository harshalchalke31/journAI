{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Projects\\python\\mainenv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import json\n",
    "from pypdf import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Projects\\\\python\\\\journAI'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromadb_path=\"./data/chroma_db\"\n",
    "pdf_folder = \".\\data\\pdf_data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model path\n",
    "model_path = r\".\\models\\deepseek-qwen-1.5B\"  # Use raw string (r\"\") to avoid escape issues\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=True)\n",
    "\n",
    "# Load the model with optimized settings\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.float16,  # Use float16 for better performance\n",
    "    device_map=\"auto\"  # Auto-detect GPU, fallback to CPU\n",
    ")\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Function to generate text\n",
    "def generate_text(prompt, max_length=1024):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)  # Send inputs to correct device\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs, max_length=max_length)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Processed and stored 0 PDF files with chunking.\n"
     ]
    }
   ],
   "source": [
    "# **1. Load Improved Embedding Model**\n",
    "embedder = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "# **2. Initialize ChromaDB**\n",
    "chroma_client = chromadb.PersistentClient(path=chromadb_path)\n",
    "collection = chroma_client.get_or_create_collection(name=\"document_vectors\")\n",
    "\n",
    "# **3. Function to Extract and Chunk PDF Text**\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts text from a PDF and splits it into smaller chunks for better retrieval.\"\"\"\n",
    "    with open(pdf_path, \"rb\") as f:\n",
    "        reader = PdfReader(f)\n",
    "        text = \"\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
    "    \n",
    "    # Split text into smaller chunks (200-500 tokens per chunk)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# **4. Ingest Multiple PDFs into Vector Store**\n",
    "documents = {}\n",
    "\n",
    "for pdf_file in os.listdir(pdf_folder):\n",
    "    if pdf_file.endswith(\".pdf\"):\n",
    "        file_path = os.path.join(pdf_folder, pdf_file)\n",
    "        chunks = extract_text_from_pdf(file_path)\n",
    "        \n",
    "        # Store chunks in ChromaDB\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            embedding = embedder.encode(chunk, convert_to_numpy=True).tolist()\n",
    "            doc_id = f\"{pdf_file}_chunk_{i}\"\n",
    "            collection.add(ids=[doc_id], embeddings=[embedding], metadatas=[{\"filename\": pdf_file, \"content\": chunk}])\n",
    "\n",
    "print(f\"ðŸ“„ Processed and stored {len(documents)} PDF files with chunking.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# **Function to Clean Retrieved Text**\n",
    "def clean_text(text):\n",
    "    \"\"\"Removes artifacts like <EOS>, <pad>, and fixes tokenized fragments.\"\"\"\n",
    "    text = text.replace(\"<EOS>\", \"\").replace(\"<pad>\", \"\").strip()  # Remove tokens\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # Fix spacing issues\n",
    "    sentences = text.split(\". \")  # Split into sentences\n",
    "    \n",
    "    # Keep only meaningful sentences (length > 5 words)\n",
    "    clean_sentences = [s.strip() for s in sentences if len(s.split()) > 5]\n",
    "    \n",
    "    return \". \".join(clean_sentences)\n",
    "\n",
    "# **Updated Retrieval Function**\n",
    "def retrieve_docs(query, top_k=5):\n",
    "    \"\"\"Retrieves most relevant document chunks and cleans the text.\"\"\"\n",
    "    query_vector = embedder.encode([query], convert_to_numpy=True).tolist()\n",
    "    results = collection.query(query_embeddings=query_vector, n_results=top_k)\n",
    "    \n",
    "    retrieved_docs = [doc[\"content\"] for doc in results[\"metadatas\"][0]]\n",
    "    \n",
    "    # Clean and join retrieved context\n",
    "    cleaned_docs = \"\\n\\n\".join([clean_text(doc) for doc in retrieved_docs if doc])\n",
    "    \n",
    "    return cleaned_docs\n",
    "\n",
    "def generate_response(query):\n",
    "    \"\"\"Retrieves relevant docs, structures prompt, and generates only the response.\"\"\"\n",
    "    retrieved_context = retrieve_docs(query)\n",
    "\n",
    "    prompt1 = f\"\"\"\n",
    "    You are an AI assistant with access to research papers and textbooks.\n",
    "    Use the retrieved knowledge to generate a structured and accurate answer.\n",
    "\n",
    "    **Context from Documents:**\n",
    "    {retrieved_context}\n",
    "\n",
    "    **Question:**\n",
    "    {query}\n",
    "\n",
    "    ### Response:\n",
    "    \"\"\"\n",
    "    print('At Response 1 stage')\n",
    "    inputs = tokenizer(prompt1, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs, max_length=1024)\n",
    "\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # **Extract only the response by removing everything before \"### Response:\"**\n",
    "    if \"### Response:\" in generated_text:\n",
    "        response = generated_text.split(\"### Response:\")[-1].strip()\n",
    "    else:\n",
    "        response = generated_text.strip()\n",
    "\n",
    "    print('At summarization stage')\n",
    "    prompt2= f\"\"\"Summarize the given text in clear, concise and professional manner. \n",
    "    Elaborate on any mathematical formulae, explanation needed to explain the concept described in the text.\n",
    "    \\nInput text:\\n {response}\n",
    "\n",
    "    ### Response:\n",
    "    \"\"\"\n",
    "\n",
    "    inputs2 = tokenizer(prompt2,return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output2 = model.generate(**inputs2, max_length=1024)\n",
    "    generated_text2 = tokenizer.decode(output2[0],skip_special_tokens=True)\n",
    "\n",
    "    if \"### Response:\" in generated_text2:\n",
    "        response2 = generated_text2.split(\"### Response:\")[-1].strip()\n",
    "    else:\n",
    "        response2 = generated_text2.strip() \n",
    "\n",
    "    return response2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At Response 1 stage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At summarization stage\n",
      "\n",
      "ðŸ”¹ Model Response:\n",
      " The segment anything model is a neural network designed for semantic segmentation tasks, where each pixel is assigned to a specific class. It uses a graph-based approach, with nodes representing pixels or regions and edges representing relationships. The architecture includes multiple layers, refining segmentation masks through skip connections, which preserve low-level features while capturing higher-level information. Attention mechanisms enhance focus, improving accuracy and efficiency. Performance is influenced by object class complexity, image size, and computational resources. This model has achieved top-tier results on benchmark datasets, making it a versatile tool for medical imaging and autonomous driving.\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "query = \"Explainthe segment anything model in detail!\"\n",
    "response = generate_response(query)\n",
    "\n",
    "# print(\"\\nðŸ”¹ Retrieved Context (Cleaned):\\n\", retrieve_docs(query))\n",
    "pprint.pprint(\"\\nðŸ”¹ Model Response:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The segment anything model is a neural network designed for semantic '\n",
      " 'segmentation tasks, where each pixel is assigned to a specific class. It '\n",
      " 'uses a graph-based approach, with nodes representing pixels or regions and '\n",
      " 'edges representing relationships. The architecture includes multiple layers, '\n",
      " 'refining segmentation masks through skip connections, which preserve '\n",
      " 'low-level features while capturing higher-level information. Attention '\n",
      " 'mechanisms enhance focus, improving accuracy and efficiency. Performance is '\n",
      " 'influenced by object class complexity, image size, and computational '\n",
      " 'resources. This model has achieved top-tier results on benchmark datasets, '\n",
      " 'making it a versatile tool for medical imaging and autonomous driving.']\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(response.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Response:\n",
      " Explain quantum computing in simple terms. How do you get a quantum computer to work? What are the main advantages and disadvantages of quantum computing compared to classical computing? Can you explain in simple terms the difference between quantum computing and classical computing? Why is quantum computing important in today's world? How do you get a quantum computer to work? What are the main advantages and disadvantages of quantum computing compared to classical computing? Can you explain in simple terms the difference between quantum computing and classical computing? Why is quantum computing important in today's world?\n",
      "\n",
      "I need to explain quantum computing in simple terms. How do you get a quantum computer to work? What are the main advantages and disadvantages of quantum computing compared to classical computing? Can you explain in simple terms the difference between quantum computing and classical computing? Why is quantum computing important in today's world? How do you get a quantum computer to work? What are the main advantages and disadvantages of quantum computing compared to classical computing? Can you explain in simple terms the difference between quantum computing and classical computing? Why is quantum computing important in today's world?\n",
      "\n",
      "Wait, the user provided this again, but maybe they meant to ask about a different topic? Or perhaps they made a typo. The original query was about quantum computing, so perhaps they just copied it twice. Maybe they want a comprehensive explanation of quantum computing, the process of getting a quantum computer to work, the advantages and disadvantages compared to classical computing, and why it's important now.\n",
      "\n",
      "I need to make sure I address each of these points clearly and simply. I should explain quantum computing in basic terms, then discuss how it works, its advantages, and its limitations. I should also explain the difference between quantum and classical computing in simple terms.\n",
      "\n",
      "Additionally, I need to highlight why quantum computing is important in today's world, maybe touching on its potential applications like cryptography, optimization problems, and more.\n",
      "\n",
      "I should avoid jargon and keep the language straightforward. Maybe use analogies that people can relate to, like comparing quantum computers to something they might already know, like a computer, but in a more abstract way.\n",
      "\n",
      "Let me think about each section:\n",
      "\n",
      "1. Quantum Computing: Simple explanation. Maybe compare it to a regular computer but with some twist. Maybe something like a computer that can process information in a different way.\n",
      "\n",
      "2. How to Get a Quantum Computer to Work: Steps. Probably need to explain qubits, quantum bits, how they're used, and maybe some operations like quantum teleportation or superposition.\n",
      "\n",
      "3. Advantages vs. Disadvantages: Compare to classical computing. Maybe list specific advantages like speed, security, etc., and disadvantages like cost, complexity, etc.\n",
      "\n",
      "4. Difference Between Quantum and Classical Computing: Explanation in simple terms. Maybe talk about how classical computers use bits and quantum computers use qubits, and what that means for their processing power and speed.\n",
      "\n",
      "5. Why is Quantum Computing Important Today? Maybe give examples of how it's used, like in drug discovery, optimization, or encryption.\n",
      "\n",
      "I should structure each part clearly, maybe using bold headings for each section, but since I'm avoiding markdown, I'll just list them with clear headings.\n",
      "\n",
      "Also, for each question, I need to address the user's needs. They might be a student or someone with basic computer knowledge looking to understand quantum computing.\n",
      "\n",
      "I should also make sure the language is accessible, avoiding overly technical terms unless necessary. Maybe use phrases like \"made up particles\" or \"quantum states\" instead of jargon.\n",
      "\n",
      "Let me outline the structure:\n",
      "\n",
      "1. Introduction to Quantum Computing: Basic concept, difference from classical, why important.\n",
      "\n",
      "2. How Quantum Computers Work: Explanation of qubits, quantum bits, operations.\n",
      "\n",
      "3. Advantages of Quantum Computing: Speed, parallel processing, error correction, etc.\n",
      "\n",
      "4. Disadvantages: Cost, complexity, limited qubits, etc.\n",
      "\n",
      "5. Difference Between Quantum and Classical Computing: Comparison in simple terms.\n",
      "\n",
      "6. Why Quantum Computing Matters Today: Applications, security, etc.\n",
      "\n",
      "I think that covers all the points. Now, I'll try to write each section clearly, using simple language and avoiding complex terms.\n",
      "\n",
      "I should also make sure each section is concise, maybe around 1-2 paragraphs, and include examples where possible to make it relatable.\n",
      "\n",
      "For the process of getting a quantum computer to work, I might need to explain the physical components involved, like superconductors or trapped ions, but perhaps keep it simple by mentioning qubits and quantum gates.\n",
      "\n",
      "In the advantages, I can list specific benefits like faster computations, secure data processing, etc. For disadvantages, mention the high cost, complex algorithms, limited qubits, etc.\n",
      "\n",
      "The difference section can highlight the fundamental difference between qubits and classical bits, emphasizing the \"q\" in quantum.\n",
      "\n",
      "Finally, the importance section can provide real-world applications and why quantum computing is a hot area of research and development.\n",
      "\n",
      "Alright, I think I have a plan. Now, I'll proceed to write each section in simple terms, ensuring clarity and accessibility.\n",
      "</think>\n",
      "\n",
      "**Exploring Quantum Computing:\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Explain quantum computing in simple terms.\"\n",
    "response = generate_text(prompt)\n",
    "print(\"\\nGenerated Response:\\n\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mainenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
